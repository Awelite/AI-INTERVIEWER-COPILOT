{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4Tw9mFf7rSjV8CqI/kq8S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Awelite/AI-INTERVIEWER-COPILOT/blob/main/hybridATS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **⚓** HYBRID ATS MODEL"
      ],
      "metadata": {
        "id": "Li2hhlbXttO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "UZezifKwbBMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "917efd83-91fc-47b0-af07-9eacdb4c5c48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ROOT = \"/content/drive/MyDrive/ATS_Project_Files\"\n",
        "MODELS_DIR = f\"{PROJECT_ROOT}/models\"\n",
        "SCRIPTS_DIR = f\"{PROJECT_ROOT}/scripts\"\n",
        "\n",
        "print(\"Project Root:\", PROJECT_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBW562DWi3-q",
        "outputId": "09b7dbb3-a9ae-497c-9ec8-fe4febe70f3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project Root: /content/drive/MyDrive/ATS_Project_Files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JEmgP3orjEJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(MODELS_DIR):\n",
        "    level = root.replace(MODELS_DIR, \"\").count(os.sep)\n",
        "    indent = \" \" * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    for f in files:\n",
        "        print(f\"{indent}  - {f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Trzv3a9jEpz",
        "outputId": "357eccef-ee2e-4099-c08a-e5c8f6391a4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/\n",
            "  - resume_features_summary.csv\n",
            "  - ats_results_full.json\n",
            "  - ats_summary.csv\n",
            "  - baseline_tfidf_lr.joblib\n",
            "  modernbert_finetune/\n",
            "    finetuned/\n",
            "    runs/\n",
            "      Nov19_15-40-29_1a8659596dc9/\n",
            "        - events.out.tfevents.1763566847.1a8659596dc9.2574.0\n",
            "  sbert_lgbm/\n",
            "    - lgbm_model.pkl\n",
            "    sbert_encoder/\n",
            "      - config_sentence_transformers.json\n",
            "      - config.json\n",
            "      - model.safetensors\n",
            "      - tokenizer_config.json\n",
            "      - special_tokens_map.json\n",
            "      - vocab.txt\n",
            "      - tokenizer.json\n",
            "      - sentence_bert_config.json\n",
            "      - modules.json\n",
            "      - README.md\n",
            "      1_Pooling/\n",
            "        - config.json\n",
            "      2_Normalize/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load ML-Based ATS (ONLY)**"
      ],
      "metadata": {
        "id": "vX3fyMaLkFDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/ATS_Project_Files\"\n",
        "\n",
        "# Load SBERT encoder (trained)\n",
        "sbert = SentenceTransformer(\n",
        "    f\"{PROJECT_ROOT}/models/sbert_lgbm/sbert_encoder\"\n",
        ")\n",
        "\n",
        "# Load LightGBM model\n",
        "lgbm_model = joblib.load(\n",
        "    f\"{PROJECT_ROOT}/models/sbert_lgbm/lgbm_model.pkl\"\n",
        ")\n",
        "\n",
        "print(\"ML-based ATS loaded successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGcAm2PPjdYT",
        "outputId": "6a71a134-c0bc-42c1-870e-eab5abd90f42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ML-based ATS loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sanity Test ML Model (NO RULE ENGINE)**"
      ],
      "metadata": {
        "id": "0I1ZCr9ekKmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity test ML model (Booster-compatible)\n",
        "\n",
        "emb_r = sbert.encode(dummy_resume)\n",
        "emb_j = sbert.encode(dummy_jd)\n",
        "\n",
        "features = np.abs(emb_r - emb_j).reshape(1, -1)\n",
        "\n",
        "# For Booster, predict() returns probability\n",
        "prob = lgbm_model.predict(features)[0]\n",
        "\n",
        "print(\"ML probability:\", prob)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axbrq2Wlmirr",
        "outputId": "cd9e0657-3424-4b1e-d366-98c36a2c01a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ML probability: 0.9907775038316795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load RULE-BASED ATS (ISOLATED SAFE LOAD)"
      ],
      "metadata": {
        "id": "sXVyHGhWmk9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Skill Vocabulary (SIMPLE & EXPLICIT)"
      ],
      "metadata": {
        "id": "k1WWbmr_vRm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q rapidfuzz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYda2hX3og6O",
        "outputId": "9f333bb6-f40e-4326-e02b-92c612e8367b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/3.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m2.3/3.2 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/ATS_Project_Files\"\n",
        "\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "print(\"Project root added to sys.path\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwLJRo0ao-N_",
        "outputId": "d68d38d1-fdcb-4efd-f963-9268a026f5e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project root added to sys.path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "init_path = f\"{PROJECT_ROOT}/scripts/__init__.py\"\n",
        "print(\"scripts/__init__.py exists:\", os.path.exists(init_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSKc-VvOo_pf",
        "outputId": "79283e28-5f57-4ba5-dd01-9992176fbb17"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scripts/__init__.py exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from scripts.skill_match import compute_skill_match\n",
        "import re\n",
        "\n",
        "SKILL_VOCAB = [\n",
        "    \"python\", \"java\", \"c++\", \"machine learning\", \"deep learning\",\n",
        "    \"data science\", \"sql\", \"django\", \"flask\", \"nlp\",\n",
        "    \"tensorflow\", \"pytorch\", \"react\", \"node\", \"git\", \"docker\"\n",
        "]\n",
        "\n",
        "def estimate_experience_score(text):\n",
        "    # crude heuristic: count years mentioned\n",
        "    years = re.findall(r'(\\d+)\\s+years?', text.lower())\n",
        "    if not years:\n",
        "        return 50\n",
        "    max_year = max(map(int, years))\n",
        "    return min(100, max_year * 10)\n",
        "\n",
        "def estimate_formatting_score(text):\n",
        "    # heuristic: length & structure\n",
        "    if len(text.split()) > 300:\n",
        "        return 80\n",
        "    return 60\n",
        "\n",
        "def score_resume_against_jd(resume_text, jd_text):\n",
        "    skill_result = compute_skill_match(\n",
        "        resume_text,\n",
        "        jd_text,\n",
        "        SKILL_VOCAB\n",
        "    )\n",
        "\n",
        "    skill_score = skill_result[\"match_percent\"]\n",
        "    exp_score = estimate_experience_score(resume_text)\n",
        "    fmt_score = estimate_formatting_score(resume_text)\n",
        "\n",
        "    ats_score = (\n",
        "        skill_score * 0.5 +\n",
        "        exp_score * 0.3 +\n",
        "        fmt_score * 0.2\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"ats_score\": round(ats_score, 2),\n",
        "        \"skill_score\": skill_score,\n",
        "        \"experience_score\": exp_score,\n",
        "        \"formatting_score\": fmt_score,\n",
        "        \"matched_skills\": skill_result[\"matched_skills\"],\n",
        "        \"missing_skills\": skill_result[\"missing_skills\"],\n",
        "        \"timestamp\": str(datetime.now())\n",
        "    }\n"
      ],
      "metadata": {
        "id": "uzEqAXSrtTWO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Rule-Based ATS (THIS WILL WORK)"
      ],
      "metadata": {
        "id": "h_Rr2BryuFyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.score import score_resume_against_jd\n",
        "print(\"Rule-based ATS imported successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x1RM5V7uGfX",
        "outputId": "da0bf45b-93df-45db-ab9f-1ea326a77187"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule-based ATS imported successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,200p' /content/drive/MyDrive/ATS_Project_Files/scripts/skill_match.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CVKytoSzs-c_",
        "outputId": "d06af760-158b-4bbd-956b-0d59ec04a9ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import re\n",
            "\n",
            "def extract_skills_from_text(text, skill_vocab):\n",
            "    \"\"\"\n",
            "    Extracts skills mentioned in text based on predefined vocabulary.\n",
            "    \"\"\"\n",
            "    found = []\n",
            "    text_lower = text.lower()\n",
            "    for skill in skill_vocab:\n",
            "        pattern = r\"\\b\" + re.escape(skill.lower()) + r\"\\b\"\n",
            "        if re.search(pattern, text_lower):\n",
            "            found.append(skill)\n",
            "    return sorted(list(set(found)))\n",
            "\n",
            "def compute_skill_match(resume_text, jd_text, skill_vocab):\n",
            "    \"\"\"\n",
            "    Compares resume and JD skills, returns match % and missing skills.\n",
            "    \"\"\"\n",
            "    resume_skills = extract_skills_from_text(resume_text, skill_vocab)\n",
            "    jd_skills = extract_skills_from_text(jd_text, skill_vocab)\n",
            "\n",
            "    if not jd_skills:\n",
            "        return {\n",
            "            \"jd_skills\": [],\n",
            "            \"resume_skills\": resume_skills,\n",
            "            \"match_percent\": 0.0,\n",
            "            \"matched_skills\": [],\n",
            "            \"missing_skills\": []\n",
            "        }\n",
            "\n",
            "    matched = [s for s in jd_skills if s in resume_skills]\n",
            "    missing = [s for s in jd_skills if s not in resume_skills]\n",
            "\n",
            "    match_percent = (len(matched) / len(jd_skills)) * 100 if jd_skills else 0\n",
            "\n",
            "    return {\n",
            "        \"jd_skills\": jd_skills,\n",
            "        \"resume_skills\": resume_skills,\n",
            "        \"match_percent\": round(match_percent, 2),\n",
            "        \"matched_skills\": matched,\n",
            "        \"missing_skills\": missing\n",
            "    }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sanity Test"
      ],
      "metadata": {
        "id": "YTBMtq02uV8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = score_resume_against_jd(\n",
        "    \"Python developer with ML experience\",\n",
        "    \"Looking for Python engineer with ML knowledge\"\n",
        ")\n",
        "\n",
        "print(out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxrKpKs0uWNS",
        "outputId": "5f97b0e0-476c-4ade-c544-958a56be7f17"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ats_score': 100.0, 'matched_skills': ['python'], 'missing_skills': [], 'resume_skills': ['python'], 'jd_skills': ['python'], 'timestamp': '2025-12-23 15:20:53.743783'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Everything (Clean Cell)"
      ],
      "metadata": {
        "id": "gjKp3as6zbf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- PATH SETUP ----\n",
        "import sys\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/ATS_Project_Files\"\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "# ---- IMPORTS ----\n",
        "from scripts.score import score_resume_against_jd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import joblib\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03qQD_qNzcxH",
        "outputId": "b46642fb-b262-4a29-d439-afd9457f5c95"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BUoNaczBzgEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SBERT encoder\n",
        "sbert = SentenceTransformer(\n",
        "    f\"{PROJECT_ROOT}/models/sbert_lgbm/sbert_encoder\"\n",
        ")\n",
        "\n",
        "# Load LightGBM classifier\n",
        "lgbm_model = joblib.load(\n",
        "    f\"{PROJECT_ROOT}/models/sbert_lgbm/lgbm_model.pkl\"\n",
        ")\n",
        "\n",
        "print(\"ML models loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGhhWheWzgee",
        "outputId": "4a7adb4b-6d7d-48ba-b6c7-8ffa6668fa0f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ML models loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_hybrid_ats(resume_text, jd_text):\n",
        "    \"\"\"\n",
        "    Hybrid ATS:\n",
        "    30% Rule-based + 70% ML-based\n",
        "    \"\"\"\n",
        "\n",
        "    # ----- RULE-BASED ATS -----\n",
        "    rule_out = score_resume_against_jd(resume_text, jd_text)\n",
        "    rule_score = rule_out[\"ats_score\"]  # 0–100\n",
        "\n",
        "    # ----- ML-BASED ATS -----\n",
        "    emb_resume = sbert.encode(resume_text)\n",
        "    emb_jd = sbert.encode(jd_text)\n",
        "\n",
        "    features = np.abs(emb_resume - emb_jd).reshape(1, -1)\n",
        "\n",
        "    # LightGBM Booster returns probability directly\n",
        "    ml_prob = float(lgbm_model.predict(features)[0])\n",
        "    ml_score = ml_prob * 100\n",
        "\n",
        "    # ----- HYBRID MERGE -----\n",
        "    final_score = round(\n",
        "        0.3 * rule_score + 0.7 * ml_score,\n",
        "        2\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"final_ats_score\": final_score,\n",
        "        \"rule_score\": round(rule_score, 2),\n",
        "        \"ml_probability\": round(ml_prob, 4),\n",
        "        \"rule_details\": rule_out\n",
        "    }\n"
      ],
      "metadata": {
        "id": "K-vNHbOTzi2_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gaKcQHkqzsqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resume_text = \"Python developer with 3 years experience in machine learning and data science\"\n",
        "jd_text = \"Hiring Python engineer with ML and data science skills\"\n",
        "\n",
        "output = run_hybrid_ats(resume_text, jd_text)\n",
        "output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upjJw3Umzs72",
        "outputId": "b07d4b0e-fcc4-4da9-be3d-00e55cfeed66"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'final_ats_score': 99.56,\n",
              " 'rule_score': 100.0,\n",
              " 'ml_probability': 0.9938,\n",
              " 'rule_details': {'ats_score': 100.0,\n",
              "  'matched_skills': ['data science', 'python'],\n",
              "  'missing_skills': [],\n",
              "  'resume_skills': ['data science', 'machine learning', 'python'],\n",
              "  'jd_skills': ['data science', 'python'],\n",
              "  'timestamp': '2025-12-23 15:24:39.940147'}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/ATS_Project_Files/scripts/hybrid_ats.py\n",
        "import sys\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import joblib\n",
        "\n",
        "# Ensure project root is visible\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/ATS_Project_Files\"\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "from scripts.score import score_resume_against_jd\n",
        "\n",
        "\n",
        "# Load ML models once (global)\n",
        "SBERT_PATH = f\"{PROJECT_ROOT}/models/sbert_lgbm/sbert_encoder\"\n",
        "LGBM_PATH = f\"{PROJECT_ROOT}/models/sbert_lgbm/lgbm_model.pkl\"\n",
        "\n",
        "sbert = SentenceTransformer(SBERT_PATH)\n",
        "lgbm_model = joblib.load(LGBM_PATH)\n",
        "\n",
        "\n",
        "def run_hybrid_ats(resume_text, jd_text):\n",
        "    \"\"\"\n",
        "    Hybrid ATS Engine\n",
        "    30% Rule-based + 70% ML-based\n",
        "    \"\"\"\n",
        "\n",
        "    # ----- RULE-BASED ATS -----\n",
        "    rule_out = score_resume_against_jd(resume_text, jd_text)\n",
        "    rule_score = rule_out[\"ats_score\"]\n",
        "\n",
        "    # ----- ML-BASED ATS -----\n",
        "    emb_resume = sbert.encode(resume_text)\n",
        "    emb_jd = sbert.encode(jd_text)\n",
        "\n",
        "    features = np.abs(emb_resume - emb_jd).reshape(1, -1)\n",
        "\n",
        "    # LightGBM Booster returns probability\n",
        "    ml_prob = float(lgbm_model.predict(features)[0])\n",
        "    ml_score = ml_prob * 100\n",
        "\n",
        "    # ----- HYBRID MERGE -----\n",
        "    final_score = round(\n",
        "        0.3 * rule_score + 0.7 * ml_score,\n",
        "        2\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"final_ats_score\": final_score,\n",
        "        \"rule_score\": round(rule_score, 2),\n",
        "        \"ml_probability\": round(ml_prob, 4),\n",
        "        \"rule_details\": rule_out\n",
        "    }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3i7Svac0Y8I",
        "outputId": "21c25f30-9323-40ec-a105-845c71aa067c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/drive/MyDrive/ATS_Project_Files/scripts/hybrid_ats.py\n"
          ]
        }
      ]
    }
  ]
}